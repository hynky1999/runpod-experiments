{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before we start tunning let's see how the models perform with few shots\n",
    "\n",
    "\n",
    "# Models\n",
    "# We use instruct models only as i have no idea how I would \"prompt\" completion models\n",
    "# with current setting\n",
    "models = [\n",
    "    \"NousResearch/Llama-2-7b-chat-hf\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"codellama/CodeLlama-7b-Instruct-hf\",\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the CodeLlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\")\n",
    "from transformers import AutoModelForCausalLM\n",
    "x = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"system\", \"content\": \"Generate a fitting name for the provided function\"},{\"role\": \"user\", \"content\": \"Create a code which sums up two numbers\"}],\n",
    "    tokenize=True, return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model  = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\", torch_dtype=torch.bfloat16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "result = model.generate(x.to(\"cuda\"), max_length=100, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dst = load_from_disk(\"../s3/hf/datasets/python_code_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first 100 examples\n",
    "examples = dst[\"train\"].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source_code', 'function_name'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "def apply_template(x):\n",
    "    return {\"text\": tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"system\", \"content\": \"Generate a fitting name for the provided function\"},{\"role\": \"user\", \"content\": x[\"source_code\"]}],\n",
    "        tokenize=False)\n",
    "    }\n",
    "examples_tokenized = examples.map(apply_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Generate a fitting name for the provided function\n",
      "<</SYS>>\n",
      "\n",
      "def x(self):\n",
      "    import scipy\n",
      "    start = self._start_time\n",
      "    seg = 1 - self.segmentation.astype(np.int8)\n",
      "    self.stats['low level object voxels'] = np.sum(seg)\n",
      "    self.stats['low level image voxels'] = np.prod(seg.shape)\n",
      "    seg_border = scipy.ndimage.filters.laplace(seg, mode='constant')\n",
      "    logger.debug('seg_border: %s', scipy.stats.describe(seg_border, axis=None))\n",
      "    seg_border[seg_border != 0] = 1\n",
      "    logger.debug('seg_border: %s', scipy.stats.describe(seg_border, axis=None))\n",
      "    boundary_dilatation_distance = self.segparams[\n",
      "        'boundary_dilatation_distance']\n",
      "    seg = scipy.ndimage.morphology.binary_dilation(seg_border, np.ones([\n",
      "        boundary_dilatation_distance * 2 + 1, boundary_dilatation_distance *\n",
      "        2 + 1, boundary_dilatation_distance * 2 + 1]))\n",
      "    if self.keep_temp_properties:\n",
      "        self.temp_msgc_lowres_discontinuity = seg\n",
      "    else:\n",
      "        self.temp_msgc_lowres_discontinuity = None\n",
      "    if self.debug_images:\n",
      "        import sed3\n",
      "        pd = sed3.sed3(seg_border)\n",
      "        pd.show()\n",
      "        pd = sed3.sed3(seg)\n",
      "        pd.show()\n",
      "    self.stats['t3'] = time.time() - start\n",
      "    return seg [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(examples_tokenized[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s><s> [INST] <<SYS>>\\nGenerate a fitting name for the provided function\\n<</SYS>>\\n\\ndef x(self):\\n    import scipy\\n    start = self._start_time\\n    seg = 1 - self.segmentation.astype(np.int8)\\n    self.stats[\\'low level object voxels\\'] = np.sum(seg)\\n    self.stats[\\'low level image voxels\\'] = np.prod(seg.shape)\\n    seg_border = scipy.ndimage.filters.laplace(seg, mode=\\'constant\\')\\n    logger.debug(\\'seg_border: %s\\', scipy.stats.describe(seg_border, axis=None))\\n    seg_border[seg_border != 0] = 1\\n    logger.debug(\\'seg_border: %s\\', scipy.stats.describe(seg_border, axis=None))\\n    boundary_dilatation_distance = self.segparams[\\n        \\'boundary_dilatation_distance\\']\\n    seg = scipy.ndimage.morphology.binary_dilation(seg_border, np.ones([\\n        boundary_dilatation_distance * 2 + 1, boundary_dilatation_distance *\\n        2 + 1, boundary_dilatation_distance * 2 + 1]))\\n    if self.keep_temp_properties:\\n        self.temp_msgc_lowres_discontinuity = seg\\n    else:\\n        self.temp_msgc_lowres_discontinuity = None\\n    if self.debug_images:\\n        import sed3\\n        pd = sed3.sed3(seg_border)\\n        pd.show()\\n        pd = sed3.sed3(seg)\\n        pd.show()\\n    self.stats[\\'t3\\'] = time.time() - start\\n    return seg [/INST]  The provided function appears to be a part of a segmentation algorithm, specifically a step in the process of identifying low-resolution discontinuities in an image. The function takes a few inputs, including the segmentation mask, the boundary dilatation distance, and a flag to keep temporary properties.\\n\\nBased on the function\\'s name and the operations it performs, a fitting name for the function could be \"low_resolution_discontinuity_detection\". This name clearly conveys the purpose of the function and the type of discontinuity it is detecting.\\n\\nAlternatively, the function could be named \"low_resolution_boundary_detection\" or \"low_resolution_edge_detection\" to emphasize the specific aspect of the segmentation process it is involved in.</s>'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(tokenizer(examples_tokenized[0][\"text\"], return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\"), num_return_sequences=1, max_new_tokens=200)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
